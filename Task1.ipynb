{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63d5254b-e0b9-458e-affb-91154a5792b4",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ca1e6-0eed-4cc2-8608-fac068a8960b",
   "metadata": {},
   "source": [
    "1. Explique la diferencia entre descenso de gradiente, descenso de gradiente por mini batches y descenso de gradiente estocástico. Asegúrese de mencionar las ventajas y desventajas de cada enfoque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314e1c89-0f61-4b27-9a29-b08270ca461d",
   "metadata": {},
   "source": [
    "Descenso de Gradiente \n",
    "Es un metodo en el cual se calcula el gradiente de la funcion de costo con respecto a los parametros utilizando el conjunto de datos de entrenamiento.\n",
    "\n",
    "Ventajas\n",
    "- Tener una convergencia estable, ya que al utilizar todo el conjunto de datos el descenso del gradiente batch tiende a tener una convergencia mas estabale hacia el minimo global de la funcion de costo.\n",
    "- Aprovecha eficientemente el hardware, ya que este aprovecha las operaciones vectorizadas dentro de el para procesar conjuntos de datos de una buena manera.\n",
    "  \n",
    "Desventajas\n",
    "- Estas estan asociadas mas que nada por su costo, ya que el calculo del gradiente para todo el conjunto de datos puede ser intensivo en la memoria, especial para los conjuntos grandes.\n",
    "-  Requiere de mas tiempo para cada iteracion.\n",
    "\n",
    "Descenso de gradiente por Mini Batches \n",
    "Este se divide en un conjunto de datos separados por pequeños lotes y calcular el gradiente utilizando un solo lote en cada iteración.\n",
    "\n",
    "Ventajas\n",
    "- Consume una menor cantidad de memoria, ya que al utilizar lotes pequeños, se reduce el requisito de memoria.\n",
    "- Permite cierto grado de paralelización, ya que los gradientes pueden calcularse al mismo tiempo.\n",
    "\n",
    "Desventajas\n",
    "- La convergencia puede ser mas ruidosa por la variabilidad introducida por los mini lotes.\n",
    "- Requiere que el usuario ajuste el tamaño de los mini lotes.\n",
    "\n",
    "Descenso de Gradiente Estocástico \n",
    "Se utiliza un unico ejemplo de entrenamiento para poder calcular el gradiente en cada iteración.\n",
    "\n",
    "Ventajas\n",
    "- Es el mas eficiente de los tres, ya que solo necesita un ejemplo, esto permite calcular facilmente una gran cantidad de datos.\n",
    "- Menor cantidad de memoria, ya que al necesitar solo un ejemplo para ser entrenado, no seguira consumiendo memoria.\n",
    "\n",
    "Desventajas\n",
    "- La variabilidad delcalculo del gradiente por medio de un solo ejemplo puede hacer que sea mas ruidosa.\n",
    "- Es menos eficiente  para el hardware especializado, ya que puede que no aproveche las operaciones vectorizadas.\n",
    "\n",
    "Extraido de:\n",
    "StatQuest with Josh Starmer. (2019, 13 mayo). Stochastic gradient descent, clearly explained!!! [Vídeo]. YouTube. https://www.youtube.com/watch?v=vMh0zPT0tLI\n",
    "StatQuest with Josh Starmer. (2019a, febrero 5). Gradient descent, Step-by-Step [Vídeo]. YouTube. https://www.youtube.com/watch?v=sDv4f4s2SB8\n",
    "codebasics. (2020, 18 agosto). Stochastic gradient descent vs batch gradient descent vs mini batch gradient descent |DL Tutorial 14 [Vídeo]. YouTube. https://www.youtube.com/watch?v=IU5fuoYBTAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc955a-3282-4876-8ae6-4c423a3b5d70",
   "metadata": {},
   "source": [
    "2. Compare y contraste técnicas de extracción de features (feature extraction) y selección de features (feature selection) en machine learning. De ejemplos de escenarios donde cada técnica sería más apropiada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79420eeb-0dcd-4336-b76a-311e583c97f9",
   "metadata": {},
   "source": [
    "El feature extraction transforma los datos originales de un nuevo espacio, ademas mas compleja, ya que implica la construccion de nuevas caracteristicas, es mas directa y selecciona las caracteristicas existentes y tambien es importante mencionar que el feature extraction utiliza modelos mas complejos o en casos donde las relaciones entre caracteristicas no son lineales.\n",
    "\n",
    "El feature selection conserva la caracteristicas originales seleccionando un subconjunto de ellas, mayormente trabaja con modelos lineales, el feature selection es mas popular cuando se busca mantener la interpretabilidad del modelo, ya que se puede identificar y comprender las caracteristicas seleccionadas.\n",
    "\n",
    "\n",
    "Para el ejemplo se utilizaran escenarios similares y se explicara el porque del uso del feature.\n",
    "\n",
    "Ejemplo feature extraction \n",
    "- Se puede utilizar en el reconocimiento facial en la extraccion de datos con imagenes, se utiliza este feature porque las imagenes tienen una alta dimensionalidad por la cantidad de pixeles.\n",
    "\n",
    "Ejemplo de feature selection\n",
    "- Se puede utilizar en el reconocimiento facial, ya que si se conocen ciertos atributos faciales especificos, como la forma de la boca u ojos, se puede identificar ala persona. Se utiliza este feature ya que la seleccion de caracteristicas permiten identificar y utilizar directamente esas caracteristicas especiales, facilitando la interpretacion y comprension del modelo.\n",
    "\n",
    "Extraido de:\n",
    "Cassie Kozyrkov. (2022, 15 mayo). MFML 115 - using AI for automatic feature extraction [Vídeo]. YouTube. https://www.youtube.com/watch?v=vOwtezUlrcg\n",
    "Cognitive Class. (2017, 21 abril). Machine Learning - dimensionality reduction - feature extraction & selection [Vídeo]. YouTube. https://www.youtube.com/watch?v=AU_hBML2H1c\n",
    "https://www.youtube.com/watch?v=pr5LXi4U10c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16085db7-3473-49d5-b0e3-1185daf2efa6",
   "metadata": {},
   "source": [
    "3. Describa la arquitectura y el funcionamiento de un perceptrón de una sola capa (un tipo de red neuronal sin backpropagation). Explique cómo aprende y la forma en la que actualiza sus parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b93905-da04-4096-b597-436ce3d4a661",
   "metadata": {},
   "source": [
    "Una perceptron de una sola capa es la forma mas basica de una red neuronal y se utiliza para realizar clasificador binaria. Su arquitectura consta de una única capa de neuronas conocida como capa de salida y cada entrada se conecta directamente a cada neurona de salida. No hay capas ocultas en este tipo de perceptrón.La arquitectura se representa de la siguiente manera:\n",
    "\n",
    "Entradas(x1, x2, x3, ... , xn) --> [Neuronas de salida] --> Salida(y)\n",
    "\n",
    "Cada conexion entre una entrada y una neurona de salida tienen un peso asociado (w1, w2, w3, ... , wn) y el perceptrón realiza una suma ponderadade las multiplicadas por sus respectivos pesos. La salida del perceptrón se determina aplicando una funcion de activacion al resultado de esta suma.\n",
    "El proceso de aprendizaje en el perceptrón de una sola capa implica ajustar los pesos de las conexiones para la salida se aproxime mejor a la salida deseada.\n",
    "Esto se hace mediante el siguiente procedimiento: \n",
    "1. Inicializacion de Pesos:\n",
    "   Se inicializan los pesos de manera aleatoria\n",
    "2. Calculo de la salida:\n",
    "   Se calcula la salida del perceptrón sumado el producto de cada entrada y su peso asociado\n",
    "   La salida se pasa a través de una funcion de activación (funcion escalon o la funcion sigmoide)\n",
    "3. Comparación con la salida deseada:\n",
    "   Se compara la salida calculada con las salida deseada.\n",
    "4. Actualización de pesos:\n",
    "   Se ajustan los pesos para reducir la diferencia entre la salida calculada y la salida deseada\n",
    "   La actualizacion de los pesos se realiza utilizando la regla de aprendizaje, que en el caso del perceptrón puede ser formulada de la siguiente manera:\n",
    "       Si la prediccion es incorrecta, se aumentan los pesos de las entradas que contribuyeron positivamente al error y se disminuyen los pesos de las entradas que contribuyeron al error.\n",
    "5. Repetición:\n",
    "   Los pasos 2-4 se repiten para multiples ejemplos de entrenamiento hasta que el modelo converge a una solucion que clasifica correctamente la mayoria de los ejemplos.\n",
    "\n",
    "El perceptrón de una sola capa tiene limitaciones y no puede resolver problemas que no sean linealmente separables. No utiliza el algoritmo de retropropagación, ya que no tiene capas ocultas para calcular gradientes. Este concepto sirvio como punto de partida para el desarrollo de las redes mas complejas. \n",
    "\n",
    "Extraido de:\n",
    "StatQuest with Josh Starmer. (2020, 31 agosto). The essential main ideas of neural networks [Vídeo]. YouTube. https://www.youtube.com/watch?v=CqOfi41LfDw\n",
    "3Blue1Brown. (2017, 5 octubre). But what is a neural network? | Chapter 1, Deep learning [Vídeo]. YouTube. https://www.youtube.com/watch?v=aircAruvnKk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625ab8ab-8b91-4a6b-bcd6-3a1ef371f0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
